{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "!pip install gradio\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djizkdJG3nTz",
        "outputId": "c766c28b-f0c5-4ee4-939b-0305ce258638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "eOdYcMHT2NWg",
        "outputId": "73131226-8172-4136-e424-813d520aa7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/bshall/knn-vc/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "Downloading: \"https://github.com/bshall/knn-vc/releases/download/v0.1/prematch_g_02500000.pt\" to /root/.cache/torch/hub/checkpoints/prematch_g_02500000.pt\n",
            "100%|██████████| 63.1M/63.1M [00:00<00:00, 245MB/s]\n",
            "Downloading: \"https://github.com/bshall/knn-vc/releases/download/v0.1/WavLM-Large.pt\" to /root/.cache/torch/hub/checkpoints/WavLM-Large.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing weight norm...\n",
            "[HiFiGAN] Generator loaded with 16,523,393 parameters.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.18G/1.18G [00:10<00:00, 121MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WavLM-Large loaded with 315,453,120 parameters.\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b95118e953caa9d2f9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b95118e953caa9d2f9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import tempfile\n",
        "from openai import OpenAI\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import gradio as gr\n",
        "from scipy.io import wavfile\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "knn_vc = torch.hub.load('bshall/knn-vc', 'knn_vc', prematched=True, trust_repo=True, pretrained=True, device='cpu')\n",
        "\n",
        "def voice_change(audio_in, audio_ref):\n",
        "    samplerate1, data1 = wavfile.read(audio_in)\n",
        "    samplerate2, data2 = wavfile.read(audio_ref)\n",
        "    write(\"./audio_in.wav\", samplerate1, data1)\n",
        "    write(\"./audio_ref.wav\", samplerate2, data2)\n",
        "\n",
        "    query_seq = knn_vc.get_features(\"./audio_in.wav\")\n",
        "    matching_set = knn_vc.get_matching_set([\"./audio_ref.wav\"])\n",
        "    out_wav = knn_vc.match(query_seq, matching_set, topk=4)\n",
        "    torchaudio.save('output.wav', out_wav[None], 16000)\n",
        "    return 'output.wav'\n",
        "\n",
        "\n",
        "def tts(text, model, voice, api_key):\n",
        "    if api_key == '':\n",
        "        raise gr.Error('Please enter your OpenAI API Key')\n",
        "    else:\n",
        "        try:\n",
        "            client = OpenAI(api_key=api_key)\n",
        "\n",
        "            response = client.audio.speech.create(\n",
        "                model=model, # \"tts-1\",\"tts-1-hd\"\n",
        "                voice=voice, # 'alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'\n",
        "                input=text,\n",
        "            )\n",
        "\n",
        "        except Exception as error:\n",
        "            # Handle any exception that occurs\n",
        "            raise gr.Error(\"An error occurred while generating speech. Please check your API key and try again.\")\n",
        "            print(str(error))\n",
        "\n",
        "    # Create a temp file to save the audio\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as temp_file:\n",
        "        temp_file.write(response.content)\n",
        "\n",
        "    # Get the file path of the temp file\n",
        "    temp_file_path = temp_file.name\n",
        "\n",
        "    return temp_file_path\n",
        "\n",
        "\n",
        "app = gr.Blocks()\n",
        "\n",
        "with app:\n",
        "    gr.Markdown(\"# <center>🥳🎶🎡 - OpenAI TTS + AI变声</center>\")\n",
        "    gr.Markdown(\"### <center>🌟 - 地表最强文本转语音模型 + 3秒实时AI变声，支持中文！Powered by [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech) and [KNN-VC](https://github.com/bshall/knn-vc) </center>\")\n",
        "    gr.Markdown(\"### <center>🌊 - 更多精彩应用，敬请关注[滔滔AI](http://www.talktalkai.com)；滔滔AI，为爱滔滔！💕</center>\")\n",
        "\n",
        "    with gr.Row(variant='panel'):\n",
        "      api_key = gr.Textbox(type='password', label='OpenAI API Key（在这里可以找到：https://platform.openai.com/api-keys）', placeholder='请在此填写OpenAI API Key')\n",
        "      model = gr.Dropdown(choices=['tts-1','tts-1-hd'], label='请选择模型（tts-1推理更快，tts-1-hd音质更好）', value='tts-1')\n",
        "      voice = gr.Dropdown(choices=['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'], label='请选择一个说话人', value='alloy')\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        inp_text = gr.Textbox(label=\"请填写您想生成的文本（中英文皆可）\", placeholder=\"想说却还没说的 还很多 攒着是因为想写成歌\", lines=5)\n",
        "        btn_text = gr.Button(\"一键开启真实拟声吧\", variant=\"primary\")\n",
        "\n",
        "      with gr.Column():\n",
        "        inp1 = gr.Audio(type=\"filepath\", label=\"OpenAI TTS真实拟声\", interactive=False)\n",
        "        inp2 = gr.Audio(type=\"filepath\", label=\"请上传AI变声的参照音频（决定变声后的语音音色）\")\n",
        "        btn1 = gr.Button(\"一键开启AI变声吧\", variant=\"primary\")\n",
        "      with gr.Column():\n",
        "        out1 = gr.Audio(type=\"filepath\", label=\"AI变声后的专属音频\")\n",
        "      btn_text.click(tts, [inp_text, model, voice, api_key], inp1)\n",
        "      btn1.click(voice_change, [inp1, inp2], out1)\n",
        "\n",
        "    gr.Markdown(\"### <center>注意❗：请不要生成会对个人以及组织造成侵害的内容，此程序仅供科研、学习及个人娱乐使用。</center>\")\n",
        "    gr.HTML('''\n",
        "        <div class=\"footer\">\n",
        "                    <p>🌊🏞️🎶 - 江水东流急，滔滔无尽声。 明·顾璘\n",
        "                    </p>\n",
        "        </div>\n",
        "    ''')\n",
        "\n",
        "app.launch(show_error=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kvTSPN3l4Hv7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}