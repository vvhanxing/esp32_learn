{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "!pip install gradio\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djizkdJG3nTz",
        "outputId": "c766c28b-f0c5-4ee4-939b-0305ce258638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "eOdYcMHT2NWg",
        "outputId": "73131226-8172-4136-e424-813d520aa7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/bshall/knn-vc/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "Downloading: \"https://github.com/bshall/knn-vc/releases/download/v0.1/prematch_g_02500000.pt\" to /root/.cache/torch/hub/checkpoints/prematch_g_02500000.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63.1M/63.1M [00:00<00:00, 245MB/s]\n",
            "Downloading: \"https://github.com/bshall/knn-vc/releases/download/v0.1/WavLM-Large.pt\" to /root/.cache/torch/hub/checkpoints/WavLM-Large.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing weight norm...\n",
            "[HiFiGAN] Generator loaded with 16,523,393 parameters.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.18G/1.18G [00:10<00:00, 121MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WavLM-Large loaded with 315,453,120 parameters.\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b95118e953caa9d2f9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b95118e953caa9d2f9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import tempfile\n",
        "from openai import OpenAI\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import gradio as gr\n",
        "from scipy.io import wavfile\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "knn_vc = torch.hub.load('bshall/knn-vc', 'knn_vc', prematched=True, trust_repo=True, pretrained=True, device='cpu')\n",
        "\n",
        "def voice_change(audio_in, audio_ref):\n",
        "    samplerate1, data1 = wavfile.read(audio_in)\n",
        "    samplerate2, data2 = wavfile.read(audio_ref)\n",
        "    write(\"./audio_in.wav\", samplerate1, data1)\n",
        "    write(\"./audio_ref.wav\", samplerate2, data2)\n",
        "\n",
        "    query_seq = knn_vc.get_features(\"./audio_in.wav\")\n",
        "    matching_set = knn_vc.get_matching_set([\"./audio_ref.wav\"])\n",
        "    out_wav = knn_vc.match(query_seq, matching_set, topk=4)\n",
        "    torchaudio.save('output.wav', out_wav[None], 16000)\n",
        "    return 'output.wav'\n",
        "\n",
        "\n",
        "def tts(text, model, voice, api_key):\n",
        "    if api_key == '':\n",
        "        raise gr.Error('Please enter your OpenAI API Key')\n",
        "    else:\n",
        "        try:\n",
        "            client = OpenAI(api_key=api_key)\n",
        "\n",
        "            response = client.audio.speech.create(\n",
        "                model=model, # \"tts-1\",\"tts-1-hd\"\n",
        "                voice=voice, # 'alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'\n",
        "                input=text,\n",
        "            )\n",
        "\n",
        "        except Exception as error:\n",
        "            # Handle any exception that occurs\n",
        "            raise gr.Error(\"An error occurred while generating speech. Please check your API key and try again.\")\n",
        "            print(str(error))\n",
        "\n",
        "    # Create a temp file to save the audio\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as temp_file:\n",
        "        temp_file.write(response.content)\n",
        "\n",
        "    # Get the file path of the temp file\n",
        "    temp_file_path = temp_file.name\n",
        "\n",
        "    return temp_file_path\n",
        "\n",
        "\n",
        "app = gr.Blocks()\n",
        "\n",
        "with app:\n",
        "    gr.Markdown(\"# <center>ğŸ¥³ğŸ¶ğŸ¡ - OpenAI TTS + AIå˜å£°</center>\")\n",
        "    gr.Markdown(\"### <center>ğŸŒŸ - åœ°è¡¨æœ€å¼ºæ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹ + 3ç§’å®æ—¶AIå˜å£°ï¼Œæ”¯æŒä¸­æ–‡ï¼Powered by [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech) and [KNN-VC](https://github.com/bshall/knn-vc) </center>\")\n",
        "    gr.Markdown(\"### <center>ğŸŒŠ - æ›´å¤šç²¾å½©åº”ç”¨ï¼Œæ•¬è¯·å…³æ³¨[æ»”æ»”AI](http://www.talktalkai.com)ï¼›æ»”æ»”AIï¼Œä¸ºçˆ±æ»”æ»”ï¼ğŸ’•</center>\")\n",
        "\n",
        "    with gr.Row(variant='panel'):\n",
        "      api_key = gr.Textbox(type='password', label='OpenAI API Keyï¼ˆåœ¨è¿™é‡Œå¯ä»¥æ‰¾åˆ°ï¼šhttps://platform.openai.com/api-keysï¼‰', placeholder='è¯·åœ¨æ­¤å¡«å†™OpenAI API Key')\n",
        "      model = gr.Dropdown(choices=['tts-1','tts-1-hd'], label='è¯·é€‰æ‹©æ¨¡å‹ï¼ˆtts-1æ¨ç†æ›´å¿«ï¼Œtts-1-hdéŸ³è´¨æ›´å¥½ï¼‰', value='tts-1')\n",
        "      voice = gr.Dropdown(choices=['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'], label='è¯·é€‰æ‹©ä¸€ä¸ªè¯´è¯äºº', value='alloy')\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        inp_text = gr.Textbox(label=\"è¯·å¡«å†™æ‚¨æƒ³ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆä¸­è‹±æ–‡çš†å¯ï¼‰\", placeholder=\"æƒ³è¯´å´è¿˜æ²¡è¯´çš„ è¿˜å¾ˆå¤š æ”’ç€æ˜¯å› ä¸ºæƒ³å†™æˆæ­Œ\", lines=5)\n",
        "        btn_text = gr.Button(\"ä¸€é”®å¼€å¯çœŸå®æ‹Ÿå£°å§\", variant=\"primary\")\n",
        "\n",
        "      with gr.Column():\n",
        "        inp1 = gr.Audio(type=\"filepath\", label=\"OpenAI TTSçœŸå®æ‹Ÿå£°\", interactive=False)\n",
        "        inp2 = gr.Audio(type=\"filepath\", label=\"è¯·ä¸Šä¼ AIå˜å£°çš„å‚ç…§éŸ³é¢‘ï¼ˆå†³å®šå˜å£°åçš„è¯­éŸ³éŸ³è‰²ï¼‰\")\n",
        "        btn1 = gr.Button(\"ä¸€é”®å¼€å¯AIå˜å£°å§\", variant=\"primary\")\n",
        "      with gr.Column():\n",
        "        out1 = gr.Audio(type=\"filepath\", label=\"AIå˜å£°åçš„ä¸“å±éŸ³é¢‘\")\n",
        "      btn_text.click(tts, [inp_text, model, voice, api_key], inp1)\n",
        "      btn1.click(voice_change, [inp1, inp2], out1)\n",
        "\n",
        "    gr.Markdown(\"### <center>æ³¨æ„â—ï¼šè¯·ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹ï¼Œæ­¤ç¨‹åºä»…ä¾›ç§‘ç ”ã€å­¦ä¹ åŠä¸ªäººå¨±ä¹ä½¿ç”¨ã€‚</center>\")\n",
        "    gr.HTML('''\n",
        "        <div class=\"footer\">\n",
        "                    <p>ğŸŒŠğŸï¸ğŸ¶ - æ±Ÿæ°´ä¸œæµæ€¥ï¼Œæ»”æ»”æ— å°½å£°ã€‚ æ˜Â·é¡¾ç’˜\n",
        "                    </p>\n",
        "        </div>\n",
        "    ''')\n",
        "\n",
        "app.launch(show_error=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kvTSPN3l4Hv7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}